


library(rethinking)
library(ggplot2)
options(repr.plot.width=16, repr.plot.height=8)
library(dagitty)


data(chimpanzees)
d <- chimpanzees


head(d)
summary(d)


?chimpanzees





d$treatment <- 1 + d$prosoc_left + 2 * d$condition


# verify using crosstabs (honestly not sure what this means)
xtabs(~ treatment + prosoc_left + condition, d)





m11.1 <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a,
        a ~ dnorm(0, 10)
    ),
    data=d
)


set.seed(1999)
prior <- extract.prior(m11.1)





p <- inv_logit(prior$a)
ggplot(data.frame(p=p), aes(p)) +
    geom_density(adjust=0.1)





m11.1_revised <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a,
        a ~ dnorm(0, 1.5)
    ),
    data=d
)
set.seed(1999)
prior_revised <- extract.prior(m11.1_revised)
p_revised <- inv_logit(prior_revised$a)
plot_df <- data.frame(p=c(p, p_revised), omega=rep(c(10, 1.5), each=length(p)))
ggplot(plot_df, aes(x = p, group = omega, colour = omega)) +
    geom_density(adjust=0.1)





m11.2 <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a + b[treatment],
        a ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 10)
    ),
    data=d
)

set.seed(1999)

prior <- extract.prior(m11.2, n=1e4)
p <- sapply(1:4, function(k) inv_logit(prior$a + prior$b[, k]))


head(prior)





head(p)


# here we are interested in the absolute difference for some reason?
difference_plot_df <- data.frame(
    diff = abs(p[, 1] - p[, 2]),
    omega = 10
)

ggplot(difference_plot_df, aes(diff, group = omega, colour = omega)) +
    geom_density(adjust=0.1)





m11.2_revised <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a + b[treatment],
        a ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data=d
)

set.seed(1999)

prior_revised <- extract.prior(m11.2_revised, n=1e4)
p_revised <- sapply(1:4, function(k) inv_logit(prior_revised$a + prior_revised$b[, k]))

difference_plot_df <- rbind(difference_plot_df, data.frame(
    diff = abs(p_revised[, 1] - p_revised[, 2]),
    omega = 0.5
))

ggplot(difference_plot_df, aes(diff, group = omega, colour = omega)) +
    geom_density(adjust=0.1)





m11.3 <- quap(
    alist(
        pulled_left <- dbinom(1, p),
        logit(p) <- a + b[treatment],
        a ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = d
)

set.seed(1999)

prior <- extract.prior(m11.3, n=1e4)
p <- sapply(1:4, function(k) inv_logit(prior$a + prior$b[, k]))
mean(abs(p[, 1] - p[, 2]))





# trimmed data list
dat_list <- list(
    pulled_left = d$pulled_left,
    actor = d$actor,
    treatment = as.integer(d$treatment)
)


m11.4 <- ulam(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list,
    chains = 4,
    log_lik = TRUE
)

precis(m11.4, depth = 2)


par(bg = 'white')
post <- extract.samples(m11.4)
p_left <- inv_logit(post$a)
plot(precis(as.data.frame(p_left)), xlim=c(0, 1))





par(bg = 'white')
labs <- c("R/N", "L/N", "R/P", "L/P")
plot(precis(m11.4, depth=2, pars="b"), labels=labs)





par(bg = 'white')
diffs <- list(
    db13 = post$b[, 1] - post$b[, 3],
    db24 = post$b[, 2] - post$b[, 4]
)
plot(precis(diffs))





pl <- by(d$pulled_left, list(d$actor, d$treatment), mean)
pl





par(bg = 'white')
plot(NULL, xlim=c(1, 28), ylim=c(0, 1), xlab="", ylab="Proportion Left Lever", xaxt="n", yaxt="n")
axis(2, at=c(0, 0.5, 1), labels=c(0, 0.5, 1))
abline(h=0.5, lty=2)
for (j in 1:7) abline(v=(j-1) * 4 + 4.5, lwd=0.5) # draw the vertical lines
for (j in 1:7) text((j-1) * 4 + 2.5, 1.1, concat("Actor", j), xpd=TRUE) # label each grid segment
for (j in 1:7[-2]) {
    lines( (j-1)*4 + c(1, 3), pl[j, c(1, 3)], lwd=2, col=rangi2) # prosocial on the right
    lines( (j-1)*4 + c(2, 4), pl[j, c(2, 4)], lwd=2, col=rangi2) # prosocial on the left
}

# adding in the filled and hollow points
points(1:28, t(pl), pch=16, col="white", cex=1.7) 
points(1:28, t(pl), pch=c(1, 1, 16, 16), col=rangi2, lwd=2)

yoff <- 0.01
text(1, pl[1,1] - yoff, "R/N", pos=1, cex=0.8)
text(2, pl[1,2] - yoff, "L/N", pos=3, cex=0.8)
text(3, pl[1,3] - yoff, "R/P", pos=1, cex=0.8)
text(4, pl[1,4] - yoff, "L/P", pos=3, cex=0.8)
mtext("Observed proportion")


# getting the posterior predictions
dat <- list(actor=rep(1:7, each=4), treatment=rep(1:4, times=7))
p_post <- link(m11.4, data=dat)
p_mu <- apply(p_post, 2, mean)
p_ci <- apply(p_post, 2, PI)





d$side <- d$prosoc_left + 1 # right 1, left 2
d$cond <- d$condition + 1 # no partner 1, partner 2

# the model. We add the log_lik so we can compare the models
data_list2 <- list(
    pulled_left = d$pulled_left,
    actor = d$actor,
    side = d$side,
    cond = d$cond
)

m11.5 <- ulam(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + bs[side] + bc[cond],
        a[actor] ~ dnorm(0, 1.5),
        bs[side] ~ dnorm(0, 0.5),
        bc[cond] ~ dnorm(0, 0.5)
    ),
    data=data_list2,
    chains=4,
    log_lik=TRUE
)


compare(m11.5, m11.4, func = PSIS)








# relative odds of switching from treatment 2 to treatment 4 (adding a partner)
post <- extract.samples(m11.4)
mean(exp(post$b[, 4] - post$b[, 2]))








data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2 * d$condition
d$side <- d$prosoc_left + 1 # right 1, left 2
d$cond <- d$condition + 1 # no partner 1, partner 2

d_aggregated <- aggregate(
    d$pulled_left,
    list(
        treatment = d$treatment,
        actor = d$actor,
        side = d$side,
        cond = d$cond
    ),
    sum
)
colnames(d_aggregated)[5] <- "left_pulls"
head(d_aggregated)





dat <- with(d_aggregated, list(
    left_pulls = left_pulls,
    treatment = treatment,
    actor = actor,
    side = side,
    cond = cond
))

m11.6 <- ulam(
    alist(
        left_pulls ~ dbinom(18, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat,
    chains = 4,
    log_lik = TRUE
)


par(bg = 'white')
plot(precis(m11.6, depth = 2))


compare(m11.6, m11.4, func=PSIS)





data(UCBadmit)
d <- UCBadmit
d





dat_list <- list(
    admit = d$admit,
    applications = d$applications,
    gid = ifelse(d$applicant.gender == "male", 1, 2)
)

m11.7 <- ulam(
    alist(
        admit ~ dbinom(applications, p),
        logit(p) <- a[gid],
        a[gid] ~ dnorm(0, 1.5)
    ),
    data = dat_list,
    chains = 4
)


par(bg = 'white')
precis(m11.7, depth = 2)
plot(precis(m11.7, depth = 2))





post <- extract.samples(m11.7)
diff_a <- post$a[, 1] - post$a[, 2]
diff_p <- inv_logit(post$a[, 1]) - inv_logit(post$a[, 2])
precis(list(diff_a=diff_a, diff_p=diff_p))





par(bg = 'white')
postcheck(m11.7)

# connect the points from the same department
for (i in 1:6) {
    x <- 1 + 2 * (i - 1)
    y1 <- d$admit[x] / d$applications[x]
    y2 <- d$admit[x + 1] / d$applications[x + 1]
    lines(c(x, x+1), c(y1, y2), col = rangi2, lwd = 2)
    text(x + 0.5, (y1 + y2) / 2 + 0.05, d$dept[x], cex = 0.8, col = rangi2)
}





# adding in the departmental index
dat_list$dept_id <- rep(1:6, each = 2)

m11.8 <- ulam(
    alist(
        admit ~ dbinom(applications, p),
        logit(p) <- a[gid] + delta[dept_id],
        a[gid] ~ dnorm(0, 1.5),
        delta[dept_id] ~ dnorm(0, 1.5)
    ),
    data = dat_list,
    chains = 4,
    iter = 4000
)



precis(m11.8, depth = 2)


par(bg = 'white')
plot(precis(m11.8, depth = 2))





post <- extract.samples(m11.8)
diff_a <- post$a[, 1] - post$a[, 2]
diff_p <- inv_logit(post$a[, 1]) - inv_logit(post$a[, 2])
precis(list(diff_a=diff_a, diff_p=diff_p))





pg <- with(dat_list,
    sapply(1:6, function(k) {
        applications[dept_id == k]/sum(applications[dept_id == k])
    })
)
rownames(pg) <- c("Male", "Female")
colnames(pg) <- unique(d$dept)
round(pg, 2)





library(dagitty)

par(bg = 'white')
dag <- dagitty("dag{G -> D -> A; G -> A}")
plot(dag)





library(dagitty)

dag <- dagitty('dag{
    G[pos="0, 0"]
    A[pos="1, 0"]
    D[pos="0.5, -0.5"]
    U[latent,pos="1,-0.5"]
    G -> D -> A; G -> A; D <- U -> A}')
par(bg = 'white')
drawdag(dag)








data(Kline)
d <- Kline
d





d$P <- scale(log(d$population))
d$contact_id <- ifelse(d$contact == "high", 2, 1)





x <- seq(0, 100, length.out = 200)
y <- dlnorm(x, 0, 10)
ggplot(data.frame(x=x, y=y), aes(x, y)) +
    geom_line()





x <- seq(0, 100, length.out = 2000)
y1 <- dlnorm(x, 0, 10)
y2 <- dlnorm(x, 3, 0.5)
ggplot(rbind(data.frame(x=x, y=y1, label="a ~ dnorm(0, 10)"), data.frame(x=x, y=y2, label="a ~ dnorm(3, 0.5)")), aes(x, y, group = label, colour = label)) +
    geom_line()






N <- 100
a <- rnorm(N, 3, 0.5)
b <- rnorm(N, 0, 10)

x <- seq(-2, 2, length.out = 201)
plot_df <- data.frame(x = numeric(), y = numeric(), n = integer())

for (i in 1:N) {
    y <- exp(a[i] + b[i] * x)
    interim_df <- data.frame(
        x = x,
        y = y,
        n = i
    )
    plot_df <- rbind(plot_df, interim_df)
}

ggplot(
    plot_df, aes(x, y, group = n)
) +
    geom_line() +
    labs(
        x = 'Log Population',
        y = "Total Tools",
        title = "b ~ dnorm(0, 10)"
    ) +
    ylim(c(0, 100))





N <- 100
a <- rnorm(N, 3, 0.5)
b <- rnorm(N, 0, 0.2)

x <- seq(-2, 2, length.out = 201)
plot_df <- data.frame(x = numeric(), y = numeric(), n = integer())

for (i in 1:N) {
    y <- exp(a[i] + b[i] * x)
    interim_df <- data.frame(
        x = x,
        y = y,
        n = i
    )
    plot_df <- rbind(plot_df, interim_df)
}

ggplot(
    plot_df, aes(x, y, group = n)
) +
    geom_line() +
    labs(
        x = 'Log Population',
        y = "Total Tools",
        title = "b ~ dnorm(0, 0.2)"
    ) +
    ylim(c(0, 100))





x_seq <- seq(from = log(100), to = log(200000), length.out = 100)
# this is a matrix where each row corresponds to the y values for that x
lambda <- sapply(x_seq, function(x) exp(a + b * x))

plot_df <- data.frame(x = numeric(), y = numeric(), a = numeric(), b = numeric())

for (i in 1:N) {
    interim_df <- data.frame(
        x = x_seq,
        y = exp(a[i] + b[i] * x_seq),
        a = rep(a[i], length(x_seq)),
        b = rep(b[i], length(x_seq))
    )
    plot_df <- rbind(plot_df, interim_df)
}

ggplot(plot_df, aes(x, y, group = interaction(a, b))) +
    geom_line() +
    ylim(c(0, 500)) +
    labs(x = 'log population', y = 'Total tools', title = "a ~ dnorm(3, 0.5), b ~ dnorm(0, 0.2)")





raw_population_plot_df <- plot_df
raw_population_plot_df$x <- exp(raw_population_plot_df$x)

ggplot(raw_population_plot_df, aes(x, y, group = interaction(a, b))) +
    geom_line() +
    ylim(c(0, 500)) +
    labs(x = 'log population', y = 'Total tools', title = "a ~ dnorm(3, 0.5), b ~ dnorm(0, 0.2)")





dat <- list(
    T = d$total_tools,
    P = d$P,
    cid = d$contact_id
)

# intercept only
m11.9 <- ulam(
    alist(
        T ~ dpois(lambda),
        log(lambda) <- a,
        a ~ dnorm(3, 0.5)
    ),
    data = dat,
    chains = 4,
    log_lik = TRUE
)

# interaction model
m11.10 <- ulam(
    alist(
        T ~ dpois(lambda),
        log(lambda) <- a[cid] + b[cid] * P,
        a[cid] ~ dnorm(3, 0.5),
        b[cid] ~ dnorm(0, 0.2)
    ),
    data = dat,
    chains = 4,
    log_lik = TRUE
)



compare(m11.9, m11.10, func = PSIS)





k <- PSIS(m11.10, pointwise = TRUE)$k

# setting up the predictions
ns <- 100
P_seq <- seq(from = -1.4, to = 3, length.out = ns)

#low contact (cid = 1) predictions
lambda <- link(m11.10, data = data.frame(P = P_seq, cid = 1))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
low_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 1
)

# high contact (cid = 2) predictions
lambda <- link(m11.10, data = data.frame(P = P_seq, cid = 2))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
high_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 2
)

predictions <- rbind(low_contact_df, high_contact_df)
predictions$cid <- factor(predictions$cid)

plot_df <- data.frame(P = dat$P, T = dat$T, cid = factor(dat$cid), k = k)
ribbon_df <- data.frame(P = predictions$P, lower = predictions$lower, upper = predictions$upper, cid = factor(predictions$cid))
ggplot() +
    geom_point(data = plot_df, mapping = aes(x = P, y = T, shape = cid, size = 1 + normalize(k))) +
    geom_line(data = predictions, mapping = aes(P, mu, linetype = cid)) +
    geom_ribbon(data = ribbon_df, mapping = aes(x = P, ymin = lower, ymax = upper, group = cid), alpha = 0.2)  +
    coord_cartesian(ylim = c(0, 75))





# setting up the predictions
ns <- 100
P_seq <- seq(from = -5, to = 3, length.out = ns)
pop_seq <- exp(P_seq * 1.53 + 9) # 1.53 is the sd of log (population); 9 is the mean

#low contact (cid = 1) predictions
lambda <- link(m11.10, data = data.frame(P = P_seq, cid = 1))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
low_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 1
)

# high contact (cid = 2) predictions
lambda <- link(m11.10, data = data.frame(P = P_seq, cid = 2))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
high_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 2
)

predictions <- rbind(low_contact_df, high_contact_df)
predictions$cid <- factor(predictions$cid)
predictions$population <- pop_seq

plot_df <- data.frame(population = d$population, total_tools = d$total_tools, cid = factor(dat$cid), k = k, culture = d$culture)
ribbon_df <- data.frame(population = pop_seq, lower = predictions$lower, upper = predictions$upper, cid = factor(predictions$cid))
ggplot() +
    geom_point(data = plot_df, mapping = aes(x = population, y = total_tools, shape = cid, size = 1 + normalize(k))) +
    geom_text(data = plot_df, mapping = aes(x = population, y = total_tools, label = culture), hjust = 0, vjust = 2) +
    geom_line(data = predictions, mapping = aes(population, mu, linetype = cid)) +
    geom_ribbon(data = ribbon_df, mapping = aes(x = population, ymin = lower, ymax = upper, group = cid), alpha = 0.2) + 
    coord_cartesian(xlim = c(0, 300000), ylim = c(0, 75))








num_days <- 30
true_lambda <- 1.5
y <- rpois(num_days, true_lambda)





num_weeks <- 4
new_true_lambda <- 0.5
y_new <- rpois(num_weeks, new_true_lambda * 7)


y_all <- c(y, y_new)
exposure <- c(rep(1, num_days), rep(7, num_weeks))
monastery <- c(rep(0, num_days), c(rep(1, num_weeks)))
d <- data.frame(y = y_all, days = exposure, monastery = monastery)

d


# create the offset (log of the exposure)
d$log_days <- log(d$days)

m11.12 <- quap(
    alist(
        y ~ dpois(lambda),
        log(lambda) <- log_days + a + b * monastery,
        a ~ dnorm(0, 1),
        b ~ dnorm(0, 1)
    ),
    data = d
)





post <- extract.samples(m11.12)
lambda_old <- exp(post$a)
lambda_new <- exp(post$a + post$b)
precis(data.frame(lambda_old, lambda_new))


par(bg = 'white')
plot(
    precis(data.frame(lambda_old, lambda_new))
)











N <- 500 # number of individuals
income <- c(1, 2, 5)
score <- 0.5 * income

# convert scores to probabilities
p <- softmax(score[1], score[2], score[3])

# now simulate the choices
# outcome career holds event type values, not counts
career <- rep(NA, N)

# randomly choose the career for each individual
set.seed(34302)
for (i in 1:N) {
    career[i] <- sample(1:3, size = 1, prob = p)
}





# Doing it in Stan!

code_m11.13 <- "
data {
    int N; // number of individuals
    int K; // number of careers
    array[N] int career; // outcome
    vector[K] career_income;
}
parameters {
    vector[K-1] a; // intercepts
    real<lower=0> b; // association of income with choice
}
model {
    vector[K] p;
    vector[K] s;
    a ~ normal(0, 1);
    b ~ normal(0, 0.5);
    s[1] = a[1] + b * career_income[1];
    s[2] = a[2] + b * career_income[2];
    s[3] = 0; // pivot
    p = softmax(s);
    career ~ categorical(p);
}
"

dat_list <- list(
    N = N,
    K = 3,
    career = career,
    career_income = income
)
m11.13 <- stan(model_code = code_m11.13, data = dat_list, chains = 4)


precis(m11.13, 2)


par(bg = 'white')
plot(precis(m11.13, 2))





post <- extract.samples(m11.13)

# set up the logit scores
s1 <- with(post, a[, 1] + b * income[1])
s2_orig <- with(post, a[, 2] + b * income[2])
s2_new <- with(post, a[, 2] + b * income[2] * 2) # doubling the income

# compute probabilities for original and counterfactual
p_orig <- sapply(1:length(post$b), function(i) {
    softmax(c(s1[i], s2_orig[i], 0))
})
p_new <- sapply(1:length(post$b), function(i) {
    softmax(c(s1[i], s2_new[i], 0))
})

p_diff <- p_new[2, ] - p_orig[2, ]
precis(p_diff)








N <- 500

# simulate family income for each student
family_income <- runif(N)

# assign a unique coefficient to each event
b <- c(-2, 0, 2)
career <- rep(NA, N)
for (i in 1:N) {
    score <- 0.5 * (1:3) + b * family_income[i] # now we're accounting for family income
    p <- softmax(score[1], score[2], score[3])
    career[i] <- sample(1:3, size = 1, prob = p)
}

code_m11.14 <- "
    data {
        int N; // observations
        int K; // careers
        array[N] int career; // the actual careers of the individuals
        array[N] real family_income; // the family income for each student
    }
    parameters {
        vector[K-1] a; // intercepts
        vector[K-1] b; // coefficients on family income
    }
    model {
        vector[K] p;
        vector[K] s;
        a ~ normal(0, 1.5);
        b ~ normal(0, 1);
        for ( i in 1:N ) {
            for (j in 1:(K-1)) {
                s[j] = a[j] + b[j] * family_income[i];
            }
            s[K] = 0; // pivot
            p = softmax(s);
            career[i] ~ categorical(p);
        }
    }
"

dat_list <- list(N = N, K = 3, career = career, family_income = family_income)
m11.14 <- stan(model_code = code_m11.14, data = dat_list, chains = 4)


precis(m11.14, 2)








data(UCBadmit)
d <- UCBadmit

# binomial model
m_binom <- quap(
    alist(
        admit ~ dbinom(applications, p),
        logit(p) <- a,
        a ~ dnorm(0, 1.5)
    ),
    data=d
)

dat <- list(admit = d$admit, rej = d$reject)
m_poisson <- ulam(
    alist(
        admit ~ dpois(lambda1),
        rej ~ dpois(lambda2),
        log(lambda1) <- a1,
        log(lambda2) <- a2,
        c(a1, a2) ~ dnorm(0, 1.5)
    ),
    data = dat,
    chains = 3,
    cores = 3
)


# look at the posterior means
inv_logit(coef(m_binom))





k <- coef(m_poisson)
a1 <- k['a1']
a2 <- k['a2']
exp(a1) / (exp(a1) + exp(a2))











p <- 0.35
log(p / (1 - p))








exp(3.2) / (1 + exp(3.2))





exp(1.7)














exp(1.7)




















data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2 * d$condition

# trimmed data list
dat_list <- list(
    pulled_left = d$pulled_left,
    actor = d$actor,
    treatment = as.integer(d$treatment)
)

m11.4_ulam <- ulam(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list,
    chains = 4,
    log_lik = TRUE
)


m11.4_quap <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list
)


par(bg = 'white')
plot(precis(m11.4_ulam, depth = 2))
plot(precis(m11.4_quap, depth = 2))





par(bg = 'white')
plot(coeftab(m11.4_ulam, m11.4_quap))





quap_samples <- extract.samples(m11.4_quap)
a2_quap <- quap_samples[['a']][, 2]
ulam_samples <- extract.samples(m11.4_ulam)
a2_ulam <- ulam_samples[['a']][, 2]

plot_df <- rbind(
    data.frame(
        x = a2_quap, type = "Quap"
    ),
    data.frame(
        x = a2_ulam, type = "Ulam"
    )
)


ggplot(plot_df, aes(x, group = type, colour = type)) +
    geom_density(aes(y = after_stat(density)))





m11.4_ulam_relaxed <- ulam(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 10),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list,
    chains = 4,
    log_lik = TRUE
)
m11.4_quap_relaxed <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 10),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list
)


par(bg = 'white')
plot(coeftab(m11.4_ulam_relaxed, m11.4_quap_relaxed))





quap_samples <- extract.samples(m11.4_quap_relaxed)
a2_quap <- quap_samples[['a']][, 2]
ulam_samples <- extract.samples(m11.4_ulam_relaxed)
a2_ulam <- ulam_samples[['a']][, 2]

plot_df <- rbind(
    data.frame(
        x = a2_quap, type = "Quap"
    ),
    data.frame(
        x = a2_ulam, type = "Ulam"
    )
)
ggplot(plot_df, aes(x, group = type, colour = type)) +
    geom_density(aes(y = after_stat(density)))








data(Kline)
d <- Kline
d$P <- as.numeric(scale(log(d$population))) # this is required because otherwise P has a type of a 1-element list, which breaks STAN
# but for some reason didn't do that earlier
d$contact_id <- ifelse(d$contact == "high", 2, 1)

d_removed <- d[d$culture != 'Hawaii', ]



dat <- list(
    T = d$total_tools,
    P = d$P,
    cid = d$contact_id
)
dat_removed <- list(
    T = d_removed$total_tools,
    P = d_removed$P,
    cid = d_removed$contact_id
)
m11.10_original <- ulam(
    alist(
        T ~ dpois(lambda),
        log(lambda) <- a[cid] + b[cid] * P,
        a[cid] ~ dnorm(3, 0.5),
        b[cid] ~ dnorm(0, 0.2)
    ),
    data = dat,
    chains = 4,
    log_lik = TRUE
)
m11.10_removed <- ulam(
    alist(
        T ~ dpois(lambda),
        log(lambda) <- a[cid] + b[cid] * P,
        a[cid] ~ dnorm(3, 0.5),
        b[cid] ~ dnorm(0, 0.2)
    ),
    data = dat_removed,
    chains = 4,
    log_lik = TRUE
)


####### ORIGINAL

# setting up the predictions
k <- PSIS(m11.10_original, pointwise = TRUE)$k
ns <- 100
P_seq <- seq(from = -5, to = 3, length.out = ns)
pop_seq <- exp(P_seq * 1.53 + 9) # 1.53 is the sd of log (population); 9 is the mean

#low contact (cid = 1) predictions
lambda <- link(m11.10_original, data = data.frame(P = P_seq, cid = 1))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
low_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 1
)

# high contact (cid = 2) predictions
lambda <- link(m11.10_original, data = data.frame(P = P_seq, cid = 2))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
high_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 2
)

predictions <- rbind(low_contact_df, high_contact_df)
predictions$cid <- factor(predictions$cid)
predictions$population <- pop_seq

plot_df <- data.frame(population = d$population, total_tools = d$total_tools, cid = factor(dat$cid), k = k, culture = d$culture)
ribbon_df <- data.frame(population = pop_seq, lower = predictions$lower, upper = predictions$upper, cid = factor(predictions$cid))
p <- ggplot() +
    geom_point(data = plot_df, mapping = aes(x = population, y = total_tools, shape = cid, size = 1 + normalize(k))) +
    geom_text(data = plot_df, mapping = aes(x = population, y = total_tools, label = culture), hjust = 0, vjust = 2) +
    geom_line(data = predictions, mapping = aes(population, mu, linetype = cid)) +
    geom_ribbon(data = ribbon_df, mapping = aes(x = population, ymin = lower, ymax = upper, group = cid), alpha = 0.2) + 
    coord_cartesian(xlim = c(0, 300000), ylim = c(0, 75)) +
    labs(title = "Original")
print(p)

#########
# With Hawaii removed

# setting up the predictions
k <- PSIS(m11.10_removed, pointwise = TRUE)$k
ns <- 100
P_seq <- seq(from = -5, to = 3, length.out = ns)
pop_seq <- exp(P_seq * 1.53 + 9) # 1.53 is the sd of log (population); 9 is the mean

#low contact (cid = 1) predictions
lambda <- link(m11.10_removed, data = data.frame(P = P_seq, cid = 1))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
low_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 1
)

# high contact (cid = 2) predictions
lambda <- link(m11.10_removed, data = data.frame(P = P_seq, cid = 2))
lmu <- apply(lambda, 2, mean)
lci <- apply(lambda, 2, PI)
high_contact_df <- data.frame(
    P = P_seq,
    mu = lmu,
    lower = lci[1, ],
    upper = lci[2, ],
    cid = 2
)

predictions <- rbind(low_contact_df, high_contact_df)
predictions$cid <- factor(predictions$cid)
predictions$population <- pop_seq

plot_df <- data.frame(population = d_removed$population, total_tools = d_removed$total_tools, cid = factor(dat_removed$cid), k = k, culture = d_removed$culture)
ribbon_df <- data.frame(population = pop_seq, lower = predictions$lower, upper = predictions$upper, cid = factor(predictions$cid))
p <- ggplot() +
    geom_point(data = plot_df, mapping = aes(x = population, y = total_tools, shape = cid, size = 1 + normalize(k))) +
    geom_text(data = plot_df, mapping = aes(x = population, y = total_tools, label = culture), hjust = 0, vjust = 2) +
    geom_line(data = predictions, mapping = aes(population, mu, linetype = cid)) +
    geom_ribbon(data = ribbon_df, mapping = aes(x = population, ymin = lower, ymax = upper, group = cid), alpha = 0.2) + 
    coord_cartesian(xlim = c(0, 300000), ylim = c(0, 75)) +
    labs(title = "Hawaii removed")
print(p)








data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2 * d$condition

# actually the revised version
m11.1 <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a,
        a ~ dnorm(0, 1.5)
    ),
    data = d
)

m11.2 <- quap(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a + b[treatment],
        a ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 10)
    ),
    data = d
)

m11.3 <- quap(
    alist(
        pulled_left <- dbinom(1, p),
        logit(p) <- a + b[treatment],
        a ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = d
)

# trimmed data list
dat_list <- list(
    pulled_left = d$pulled_left,
    actor = d$actor,
    treatment = as.integer(d$treatment)
)

m11.4 <- ulam(
    alist(
        pulled_left ~ dbinom(1, p),
        logit(p) <- a[actor] + b[treatment],
        a[actor] ~ dnorm(0, 1.5),
        b[treatment] ~ dnorm(0, 0.5)
    ),
    data = dat_list,
    chains = 4,
    log_lik = TRUE
)


comparison <- compare(m11.1, m11.2, m11.3, m11.4)
comparison





comparison_df <- as.data.frame(comparison)
comparison_df <- cbind(model = rownames(comparison_df), comparison_df)
rownames(comparison_df) <- 1:nrow(comparison_df)
comparison_df


ggplot(data.frame(
    model = comparison_df$model,
    WAIC = comparison_df$WAIC,
    lower = comparison_df$WAIC - comparison_df$SE,
    upper = comparison_df$WAIC + comparison_df$SE
), aes(WAIC, model)) +
    geom_point() +
    geom_linerange(aes(xmin = lower, xmax = upper))








library(MASS)
data(eagles)
d <- eagles
head(d)


# modify the columns to be 0 or 1
d$P_actual <- ifelse(d$P == "L", 1, 0)
d$A_actual <- ifelse(d$A == "A", 1, 0)
d$V_actual <- ifelse(d$V == "L", 1, 0)


eagles_model_quap <- quap(
    alist(
        y ~ dbinom(n, p),
        logit(p) <- a + b_p * P_actual + b_v * V_actual * b_a * A_actual,
        a ~ dnorm(0, 1.5),
        c(b_p, b_v, b_a) ~ dnorm(0, 0.5)
    ),
    data = d
)


eagles_data <- list(
    y = d$y,
    n = d$n,
    P_actual = d$P_actual,
    V_actual = d$V_actual,
    A_actual = d$A_actual
)
eagles_model_ulam <- ulam(
    alist(
        y ~ dbinom(n, p),
        logit(p) <- a + b_p * P_actual + b_v * V_actual * b_a * A_actual,
        a ~ dnorm(0, 1.5),
        c(b_p, b_v, b_a) ~ dnorm(0, 0.5)
    ),
    data = eagles_data,
    chains = 4,
    log_lik = TRUE
)


precis(eagles_model_quap)


precis(eagles_model_ulam)


quap_df <- as.data.frame(precis(eagles_model_quap))
quap_df <- cbind(variable = rownames(quap_df), quap_df)
rownames(quap_df) <- 1:nrow(quap_df)
quap_df$model <- "Quap"
ulam_df <- as.data.frame(precis(eagles_model_ulam))
ulam_df <- cbind(variable = rownames(ulam_df), ulam_df)
rownames(ulam_df) <- 1:nrow(ulam_df)
ulam_df$model <- "Ulam"
quap_df
ulam_df


combined_df <- rbind(data.frame(
    variable = quap_df$variable,
    model = quap_df$model,
    mean = quap_df$mean,
    sd = quap_df$sd
), data.frame(
    variable = ulam_df$variable,
    model = ulam_df$model,
    mean = ulam_df$mean,
    sd = ulam_df$sd
))
combined_df$lower <- combined_df$mean - combined_df$sd
combined_df$upper <- combined_df$mean + combined_df$sd
combined_df


ggplot(combined_df, aes(mean, variable, group = interaction(variable, model), colour = model)) +
    geom_point(position=ggstance::position_dodgev(height=0.3)) +
    geom_linerange(aes(xmin = lower, xmax = upper), position=ggstance::position_dodgev(height=0.3))








samples <- extract.samples(eagles_model_ulam)
lapply(samples, head)


df <- data.frame(
    P = numeric(),
    V = numeric(),
    A = numeric(),
    logit_p = numeric()
)
for (P in c(0, 1)) {
    for (V in c(0, 1)) {
        for (A in c(0, 1)) {
            for (i in 1:length(samples[['a']])) {
                df <- rbind(
                    df,
                    data.frame(
                        P = P,
                        V = V,
                        A = A,
                        logit_p = samples[['a']][i] + samples[['b_p']][i] * P + samples[['b_v']][i] * V + samples[['b_a']][i] * A
                    )
                )
            }
        }
    }
}
df$p <- inv_logit(df$logit_p)


ggplot(df, aes(p, group = interaction(P, V, A), colour = interaction(P, V, A))) +
    geom_density(aes(y = after_stat(density)))





# CALCULATION FOR N IS NOT CORRECT - ALWAYS RETURNING 24
df$count <- rep(NA, nrow(df))
df$n <- rep(NA, nrow(df))
for (i in 1:(nrow(df))) {
    row <- df[i, ]
    P <- row[, 'P'][1]
    V <- row[, 'V'][1]
    A <- row[, 'A'][1]
    matching <- d[d$P_actual == P & d$V_actual == V & d$A_actual == A, ]
    n <- matching[, 'n'][1]
    p <- df[i, 'p']
    df[i, 'n'] <- n
    df[i, 'count'] <- rbinom(1, n, p)
}


ggplot(df, aes(count, group = interaction(P, V, A), colour = interaction(P, V, A))) +
    geom_density(aes(y = after_stat(density)))





d$I_actual <- d$P_actual * d$A_actual

eagles_data <- list(
    y = d$y,
    n = d$n,
    P_actual = d$P_actual,
    V_actual = d$V_actual,
    A_actual = d$A_actual,
    I_actual = d$I_actual
)

eagles_model_ulam_interaction <- ulam(
    alist(
        y ~ dbinom(n, p),
        logit(p) <- a + b_p * P_actual + b_v * V_actual * b_a * A_actual + b_i * I_actual,
        a ~ dnorm(0, 1.5),
        c(b_p, b_v, b_a, b_i) ~ dnorm(0, 0.5)
    ),
    data = eagles_data,
    chains = 4,
    log_lik = TRUE
)


par(bg = 'white')
plot(precis(eagles_model_ulam_interaction))
plot(precis(eagles_model_ulam))


compare(eagles_model_ulam_interaction, eagles_model_ulam, func = WAIC)








data(salamanders)
d <- salamanders
head(d)


# first let's get an idea for the relationship here
ggplot(d, aes(PCTCOVER, SALAMAN)) +
    geom_point()


# coming up with some priors
# model is 
# a ~ dpois(lambda)
# lambda <- a + b_p * P
# a ~ dnorm(???)
# b_p ~ dnorm(???)
# NB I got these priors mostly by just random guessing and fiddling about until things looked reasonable

N <- 100
a <- rnorm(N, 0, 1)
b_P <- rnorm(N, 0, 0.005)
P <- seq(0, 100, by = 1)
plot_df <- data.frame(P = numeric(), lambda = numeric(), i = numeric())
for (i in 1:N) {
    lambda <- exp(a[i] + b_P[i] * P)
    plot_df <- rbind(
        plot_df,
        data.frame(
            P = P,
            lambda = lambda,
            i = i
        )
    )
}

ggplot(d, aes(PCTCOVER, SALAMAN)) +
    geom_point() +
    geom_line(data = plot_df, aes(P, lambda, group = i), alpha = 0.2)


salamander_model <- alist(
    s ~ dpois(lambda),
    log(lambda) <- a + b_P * P,
    a ~ dnorm(0, 1),
    b_P ~ dnorm(0, 0.005)
)

data <- list(
    s = d$SALAMAN,
    P = d$PCTCOVER
)

salamander_model_quap <- quap(salamander_model, data = data)
salamander_model_ulam <- ulam(salamander_model, data = data, chains = 4, log_lik = TRUE)


par(bg = 'white')
plot(precis(salamander_model_quap))
plot(precis(salamander_model_ulam))


salamander_quap_samples <- extract.samples(salamander_model_quap)
salamander_ulam_samples <- extract.samples(salamander_model_ulam)


alpha <- 0.11
a_quap <- salamander_quap_samples[['a']]
a_quap_mean <- mean(a_quap)
a_quap_bounds <- quantile(a_quap, c(alpha / 2, 1 - alpha / 2))
a_ulam <- salamander_ulam_samples[['a']]
a_ulam_mean <- mean(a_ulam)
a_ulam_bounds <- quantile(a_ulam, c(alpha / 2, 1 - alpha / 2))

b_P_quap <- salamander_quap_samples[['b_P']]
b_P_ulam <- salamander_ulam_samples[['b_P']]
b_P_quap_mean <- mean(b_P_quap)
b_P_quap_bounds <- quantile(b_P_quap, c(alpha / 2, 1 - alpha / 2))
b_P_ulam_mean <- mean(b_P_ulam)
b_P_ulam_bounds <- quantile(b_P_ulam, c(alpha / 2, 1 - alpha / 2))

# NB This is a dumb way to do it - probably the better way would be to take the standard error and calculate the range from that
# or basically any other way
comparison_df <- data.frame(
    variable = rep(c("a", "b_P"), each = 2),
    model = rep(c("Quap", "Ulam"), 2),
    mean = c(a_quap_mean, a_ulam_mean, b_P_quap_mean, b_P_ulam_mean),
    lower = c(a_quap_bounds[1], a_ulam_bounds[1], b_P_quap_bounds[1], b_P_ulam_bounds[2]),
    upper = c(a_quap_bounds[2], a_ulam_bounds[2], b_P_quap_bounds[1], b_P_ulam_bounds[2])
)
comparison_df


ggplot(comparison_df, aes(group = interaction(variable, model), colour = model)) +
    geom_pointrange(aes(x = mean, y = variable, xmin = lower, xmax = upper), position = ggstance::position_dodgev(height = 0.3))





cover_percent <- seq(0, 100, length.out = 100)
prediction_data <- data.frame(P = cover_percent)
# why is this getting lambda? What is the link function doing here? How does it know to get this instead of s, log(p), &c.?
lambda <- link(salamander_model_ulam, data = prediction_data)


lambda_mean <- apply(lambda, 2, mean)
lambda_bounds <- apply(lambda, 2, function(x) PI(x, 1 - alpha))
plot_df <- data.frame(P = cover_percent, mean = lambda_mean, lower = lambda_bounds[1, ], upper = lambda_bounds[2, ])


ggplot() +
    geom_point(data = d, aes(PCTCOVER, SALAMAN)) +
    geom_line(data = plot_df, mapping = aes(x = P, y = mean)) +
    geom_ribbon(data = plot_df, mapping = aes(x = P, ymin = lower, ymax = upper), alpha = 0.2)





# getting the priors
N <- 100
a <- rnorm(N, 0, 1)
b_A <- rnorm(N, 0, 0.005)
A <- seq(0, 700, by = 1)
plot_df <- data.frame(A = numeric(), lambda = numeric(), i = numeric())
for (i in 1:N) {
    lambda <- exp(a[i] + b_A[i] * A)
    plot_df <- rbind(
        plot_df,
        data.frame(
            A = A,
            lambda = lambda,
            i = i
        )
    )
}

ggplot(d, aes(FORESTAGE, SALAMAN)) +
    geom_point() +
    geom_line(data = plot_df, aes(A, lambda, group = i), alpha = 0.2) +
    coord_cartesian(ylim = c(0, 100))


new_salamander_model <- alist(
    s ~ dpois(lambda),
    log(lambda) <- a + b_P * P + b_A * A,
    a ~ dnorm(0, 1),
    b_P ~ dnorm(0, 0.005),
    b_A ~ dnorm(0, 0.005)
)

data <- list(
    s = d$SALAMAN,
    P = d$PCTCOVER,
    A = d$FORESTAGE
)

forest_age_salamander_model <- ulam(new_salamander_model, data = data, chains = 4, log_lik = TRUE)


par(bg = 'white')
plot(precis(forest_age_salamander_model))





compare(forest_age_salamander_model, salamander_model_ulam)





ggplot(d, aes(PCTCOVER, FORESTAGE)) +
    geom_point() +
    geom_smooth(method = 'lm')








data(NWOGrants)
d <- NWOGrants
head(d)


summary(NWOGrants)


d$ratio <- d$awards / d$applications
ggplot(d, aes(discipline, ratio, fill = gender)) +
    geom_bar(stat = 'identity', position = position_dodge())


plot_df <- data.frame(discipline = unique(d$discipline))
plot_df$difference <- NA
for (i in 1:nrow(plot_df)) {
    relevant <- d[d$discipline == plot_df[i, 'discipline'], ]
    plot_df[i, 'difference'] <- relevant[relevant$gender == 'm', 'ratio'][1] - relevant[relevant$gender == 'f', 'ratio'][1]
}
plot_df


ggplot(plot_df, aes(discipline, difference, fill = difference < 0)) +
    geom_bar(stat = 'identity')


par(bg = 'white')
dag <- dagitty('dag{G -> D -> A; G -> A}')
drawdag(dag)


# total effect: A ~ G
head(d)


nwo_data <- list(
    applications = d$applications,
    awards = d$awards,
    gid = ifelse(d$gender == "m", 1, 2),
    did = rep(1:length(unique(d$discipline)), each = 2) # department index
)
total_effects_model <- ulam(
    alist(
        awards ~ dbinom(applications, p),
        logit(p) <- a[gid],
        a[gid] ~ dnorm(0, 1.5)
    ),
    data = nwo_data,
    chains = 4,
    log_lik = TRUE
)

indirect_effects_model <- ulam(
    alist(
        awards ~ dbinom(applications, p),
        logit(p) <- a[gid] + d[did],
        a[gid] ~ dnorm(0, 1.5),
        d[did] ~ dnorm(0, 1.5)
    ),
    data = nwo_data,
    chains = 4,
    log_lik = TRUE
)


par(bg = 'white')
plot(precis(total_effects_model, depth = 2))
plot(precis(indirect_effects_model, depth = 2))


compare(indirect_effects_model, total_effects_model, func = WAIC)








par(bg = 'white')
dag <- dagitty('dag{
    G[pos="0,0"]
    D[pos="1,0"]
    A[pos="0.5,1"]
    S[unobserved, pos="1,1"]
    G -> D -> A; G -> A; A <- S -> D;
    }')
drawdag(dag)








data(Primates301)
d <- Primates301
head(d)


summary(d)


# first, let's filter out the rows with NA
# TODO actually filter out the NA values
filtered <- d[!is.na(d$brain) & !is.na(d$social_learning) & !is.na(d$research_effort), ]
# nrow(d) - nrow(filtered)
filtered


data <- list(
    s = filtered$social_learning,
    b = normalize(log(filtered$brain))
)

primate_social_learning_model_1 <- ulam(
    alist(
        s ~ dpois(lambda),
        log(lambda) <- a + b_b * b,
        a ~ dnorm(0, 1),
        b_b ~ dnorm(0, 0.5)
    ),
    data = data,
    chains = 4,
    log_lik = TRUE
)


par(bg = 'white')
precis(primate_social_learning_model_1)
plot(precis(primate_social_learning_model_1))


samples <- extract.samples(primate_social_learning_model_1)
lapply(samples, head)


posterior_lambda_means <- apply(samples$lambda, 2, mean)
posterior_lambda_ranges <- apply(samples$lambda, 2, PI)
head(posterior_lambda_ranges)


plot_df <- data.frame(
    name = filtered$name,
    s = data$s,
    b = data$b,
    mean_lambda = posterior_lambda_means,
    lambda_lower = posterior_lambda_ranges[1, ],
    lambda_upper = posterior_lambda_ranges[2, ]
)


ggplot(plot_df, aes(name, s)) +
    geom_point() +
    geom_point(data = plot_df, mapping = aes(name, mean_lambda), colour = 'blue', position = position_dodge(width = 0.1)) +
    geom_linerange(mapping = aes(name, ymin = lambda_lower, ymax = lambda_upper), colour = 'blue', position = position_dodge(width = 0.1)) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))





data <- list(
    s = filtered$social_learning,
    b = normalize(log(filtered$brain)),
    e = log(filtered$research_effort)
)

primate_social_learning_model_2 <- ulam(
    alist(
        s ~ dpois(lambda),
        log(lambda) <- a + b_b * b + b_e * e,
        a ~ dnorm(0, 1),
        c(b_b, b_e) ~ dnorm(0, 0.5)
    ),
    data = data,
    chains = 4,
    log_lik = TRUE
)


samples <- extract.samples(primate_social_learning_model_2)
posterior_lambda_means <- apply(samples$lambda, 2, mean)
posterior_lambda_ranges <- apply(samples$lambda, 2, PI)

plot_df <- data.frame(
    name = filtered$name,
    s = data$s,
    mean_lambda = posterior_lambda_means,
    lambda_lower = posterior_lambda_ranges[1, ],
    lambda_upper = posterior_lambda_ranges[2, ]
)
ggplot(plot_df, aes(name, s)) +
    geom_point() +
    geom_point(data = plot_df, mapping = aes(name, mean_lambda), colour = 'blue', position = position_dodge(width = 0.1)) +
    geom_linerange(mapping = aes(name, ymin = lambda_lower, ymax = lambda_upper), colour = 'blue', position = position_dodge(width = 0.1)) +
    theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))





compare(primate_social_learning_model_1, primate_social_learning_model_2, func = WAIC)





par(bg = 'white')
precis(primate_social_learning_model_2)
plot(precis(primate_social_learning_model_2))





exp(1.65)





par(bg = "white")
dag <- dagitty('dag{
    S[pos="0,0"]
    B[pos="-0.5,0.5"]
    R[pos="0.5,0.5"]
    B -> S <- R; B -> R;
}')
drawdag(dag)


impliedConditionalIndependencies(dag)





par(bg = 'white')
plot(precis(primate_social_learning_model_2))



